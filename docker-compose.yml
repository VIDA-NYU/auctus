version: '2.4'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0
    restart: on-failure
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Des.enforce.bootstrap.checks=true
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - ES_HEAP_SIZE=4g
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 9200:9200
    volumes:
      - ./volumes/elasticsearch:/usr/share/elasticsearch/data
  elasticsearch_exporter:
    image: justwatch/elasticsearch_exporter:1.1.0
    restart: on-failure
    command:
      - '--es.uri=http://elasticsearch:9200'
      - '--es.cluster_settings'
      - '--es.indices'
      - '--es.indices_settings'
    ports:
      - 9114
  rabbitmq:
    image: remram/rabbitmq:3.7.8
    build:
      context: ./docker
      dockerfile: rabbitmq.dockerfile
    environment:
      - RABBITMQ_DEFAULT_USER=${AMQP_USER}
      - RABBITMQ_DEFAULT_PASS=${AMQP_PASSWORD}
    ports:
      - 8080:15672
      - 5672:5672
  redis:
    image: redis:5.0
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]
    ports:
      - 6379
    volumes:
      - ./docker/redis.conf:/usr/local/etc/redis/redis.conf
  lazo:
    image: registry.gitlab.com/vida-nyu/datamart/lazo-index-service:0.1.0
    environment:
      - DATABASE=elasticsearch
      - PORT=50051
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
    ports:
      - 50051:50051
    volumes:
      - ./volumes/datasets:/datasets
      - ./volumes/cache:/cache
  coordinator:
    build:
      context: .
      dockerfile: coordinator/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - QUERY_HOST=${QUERY_HOST}
      - MAX_CACHE_BYTES=100000000000  # 100 GB
    # CI: command: ["bash", "-c", "set -m; python -Wd -m coverage run --branch -p -m coordinator & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS; cp .coverage* /cov/"]
    ports:
      - 8001:8001
    volumes:
      # CI: - ./cov:/cov
      - ./volumes/datasets:/datasets
      - ./volumes/cache:/cache
  query:
    build:
      context: .
      dockerfile: query/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - REDIS_HOST=redis
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    ports:
      - 8002
    # CI: command: ["bash", "-c", "set -m; python -Wd -m coverage run --branch -p -m query & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS; cp .coverage* /cov/"]
    volumes:
      # CI: - ./cov:/cov
      - ./volumes/datasets:/datasets
      - ./volumes/cache:/cache
    mem_limit: 8000m
  querylb:
    build:
      context: ./docker
      dockerfile: haproxy.dockerfile
    restart: on-failure
    ports:
      - 8002:80
      - 8081:8000
    volumes:
      - ./docker/haproxy.conf:/usr/local/etc/haproxy/haproxy.cfg:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 10s
      retries: 2
  profiler:
    build:
      context: .
      dockerfile: profiler/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    # CI: command: ["bash", "-c", "set -m; python -Wd -m coverage run --branch -p -m profiler & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS; cp .coverage* /cov/"]
    volumes:
      # CI: - ./cov:/cov
      - ./volumes/datasets:/datasets
      - ./volumes/cache:/cache
  prometheus:
    image: prom/prometheus
    ports:
      - 9090:9090
    volumes:
      - ./volumes/prometheus:/prometheus
      - ./docker/prometheus.yml:/etc/prometheus/prometheus.yml
  grafana:
    image: grafana/grafana
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      #- GF_SMTP_ENABLED=true
      #- GF_SMTP_HOST=ip-of-the-host:25
      #- GF_SMTP_FROM_NAME=Datamart Development
      #- GF_SERVER_ROOT_URL=https://grafana.example.org/
    ports:
      - 3000:3000
    volumes:
      - ./volumes/grafana:/var/lib/grafana
  example_discoverer:
    build:
      context: .
      dockerfile: discovery/Dockerfile
    command: example
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    volumes:
      - ./volumes/datasets:/datasets
  test_discoverer:
    build:
      context: .
      dockerfile: discovery/Dockerfile
    command: testsuite  # NOTCI
    # CI: command: ["bash", "-c", "set -m; python -Wd -m coverage run --branch -p discovery/test_discovery.py & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS; cp .coverage* /cov/"]
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    volumes:
      # CI: - ./cov:/cov
      - ./volumes/datasets:/datasets
  socrata:
    build:
      context: .
      dockerfile: discovery/socrata/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    volumes:
      - ./volumes/cache:/cache
  noaa:
    build:
      context: .
      dockerfile: discovery/noaa/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - NOAA_TOKEN=${NOAA_TOKEN}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
