version: '2.4'
services:
  # Keep images in sync with scripts/minikube-load-images.sh

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.8.1
    restart: on-failure
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Des.enforce.bootstrap.checks=true
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - ES_HEAP_SIZE=4g
    ulimits:
      memlock:
        soft: -1
        hard: -1
    cpu_shares: 100
    ports:
      - 9200:9200
    volumes:
      - ./volumes/elasticsearch:/usr/share/elasticsearch/data
  elasticsearch-exporter:
    image: justwatch/elasticsearch_exporter:1.1.0
    restart: on-failure
    command:
      - '--es.uri=http://elasticsearch:9200'
      - '--es.cluster_settings'
      - '--es.indices'
      - '--es.indices_settings'
    cpu_shares: 100
    ports:
      - 9114
  rabbitmq:
    image: remram/rabbitmq:3.7.8
    build:
      context: ./docker
      dockerfile: rabbitmq.dockerfile
    environment:
      - RABBITMQ_DEFAULT_USER=${AMQP_USER}
      - RABBITMQ_DEFAULT_PASS=${AMQP_PASSWORD}
    cpu_shares: 100
    ports:
      - 8080:15672
      - 5672:5672
  redis:
    image: redis:6.0
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]
    cpu_shares: 100
    ports:
      - 6379
    volumes:
      - ./docker/redis.conf:/usr/local/etc/redis/redis.conf
  lazo:
    image: registry.gitlab.com/vida-nyu/datamart/lazo-index-service:0.3.0
    environment:
      - DATABASE=elasticsearch
      - PORT=50051
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
    cpu_shares: 30
    ports:
      - 50051:50051
      - 8000
    volumes:
      - ./volumes/datasets:/datasets
      - ./volumes/cache:/cache
  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
    environment:
      - API_URL=${API_URL}
    cpu_shares: 10
    ports:
      - 8001:80
  apiserver:
    build:
      context: .
      dockerfile: apiserver/Dockerfile
    environment:
      - DEBUG=${DEBUG}
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_PORT=5672
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - REDIS_HOST=redis
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
      - NOMINATIM_URL=${NOMINATIM_URL}
      - FRONTEND_URL=${FRONTEND_URL}
      - API_URL=${API_URL}
      - CUSTOM_FIELDS=${CUSTOM_FIELDS}
    cpu_shares: 10
    ports:
      - 8002
    # CI: command: ["bash", "-c", "set -m; COVERAGE_FILE=/cov/.coverage python -Wd -m coverage run --branch -p -m apiserver & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS"]
    volumes:
      # CI: - ./cov:/cov
      - ./volumes/datasets:/datasets
      - ./volumes/cache:/cache
    mem_limit: 8000m
  apilb:
    build:
      context: ./docker
      dockerfile: haproxy.dockerfile
    restart: on-failure
    ports:
      - 8002:80
      - 8081:8000
    cpu_shares: 100
    volumes:
      - ./docker/haproxy.conf:/usr/local/etc/haproxy/haproxy.cfg:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 10s
      retries: 2
  coordinator:
    build:
      context: .
      dockerfile: coordinator/Dockerfile
    environment:
      - DEBUG=${DEBUG}
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_PORT=5672
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - API_URL=${API_URL}
      - MAX_CACHE_BYTES=100000000000  # 100 GB
      - CUSTOM_FIELDS=${CUSTOM_FIELDS}
    # CI: command: ["bash", "-c", "set -m; COVERAGE_FILE=/cov/.coverage python -Wd -m coverage run --branch -p -m coordinator & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS"]
    cpu_shares: 100
    ports:
      - 8003:8003
    volumes:
      # CI: - ./cov:/cov
      - ./volumes/datasets:/datasets
      - ./volumes/cache:/cache
  profiler:
    build:
      context: .
      dockerfile: profiler/Dockerfile
    environment:
      - DEBUG=${DEBUG}
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_PORT=5672
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
      - NOMINATIM_URL=${NOMINATIM_URL}
    # CI: command: ["bash", "-c", "set -m; COVERAGE_FILE=/cov/.coverage python -Wd -m coverage run --branch -p -m profiler & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS"]
    cpu_shares: 10
    volumes:
      # CI: - ./cov:/cov
      - ./volumes/datasets:/datasets
      - ./volumes/cache:/cache
  prometheus:
    image: prom/prometheus:v2.19.3
    cpu_shares: 100
    ports:
      - 9090:9090
    volumes:
      - ./volumes/prometheus:/prometheus
      - ./docker/prometheus.yml:/etc/prometheus/prometheus.yml
  grafana:
    image: grafana/grafana:6.7.3
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      #- GF_SMTP_ENABLED=true
      #- GF_SMTP_HOST=ip-of-the-host:25
      #- GF_SMTP_FROM_NAME=Datamart Development
      #- GF_SERVER_ROOT_URL=https://grafana.example.org/
    cpu_shares: 100
    ports:
      - 3000:3000
    volumes:
      - ./volumes/grafana:/var/lib/grafana
  example-discoverer:
    build:
      context: .
      dockerfile: discovery/Dockerfile
    command: example
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_PORT=5672
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    cpu_shares: 10
    volumes:
      - ./volumes/datasets:/datasets
  test-discoverer:
    build:
      context: .
      dockerfile: discovery/Dockerfile
    command: testsuite  # NOTCI
    # CI: command: ["bash", "-c", "set -m; COVERAGE_FILE=/cov/.coverage python -Wd -m coverage run --branch -p discovery/test_discovery.py & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS"]
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_PORT=5672
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    cpu_shares: 10
    volumes:
      # CI: - ./cov:/cov
      - ./volumes/datasets:/datasets
  socrata:
    build:
      context: .
      dockerfile: discovery/socrata/Dockerfile
    cpu_shares: 10
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_PORT=5672
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
  zenodo:
    build:
      context: .
      dockerfile: discovery/zenodo/Dockerfile
    cpu_shares: 10
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_PORT=5672
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
      - ZENODO_TOKEN=${ZENODO_TOKEN}
  uaz-indicators:
    build:
      context: .
      dockerfile: discovery/uaz_indicators/Dockerfile
    cpu_shares: 10
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_PORT=5672
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    volumes:
      - ./volumes/datasets:/datasets
  noaa:
    build:
      context: .
      dockerfile: discovery/noaa/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_PORT=5672
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - NOAA_TOKEN=${NOAA_TOKEN}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    cpu_shares: 10
